2023-02-10 01:09:56,844 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /data/apps/cuda/11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (GCC) 7.3.0
PyTorch: 1.10.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0+cu111
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.28.1+c14dd6c
------------------------------------------------------------

2023-02-10 01:09:57,063 - mmdet - INFO - Distributed training: False
2023-02-10 01:09:57,212 - mmdet - INFO - Config:
model = dict(
    type='RetinaNet',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch',
        init_cfg=dict(type='Pretrained', checkpoint='torchvision://resnet50')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        start_level=1,
        add_extra_convs='on_input',
        num_outs=5),
    bbox_head=dict(
        type='RetinaHead',
        num_classes=20,
        in_channels=256,
        stacked_convs=4,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            octave_base_scale=4,
            scales_per_octave=3,
            ratios=[0.5, 1.0, 2.0],
            strides=[8, 16, 32, 64, 128]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='FocalLoss',
            use_sigmoid=True,
            gamma=2.0,
            alpha=0.25,
            loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    train_cfg=dict(
        assigner=dict(
            type='MaxIoUAssigner',
            pos_iou_thr=0.5,
            neg_iou_thr=0.4,
            min_pos_iou=0,
            ignore_iof_thr=-1),
        allowed_border=-1,
        pos_weight=-1,
        debug=False),
    test_cfg=dict(
        nms_pre=1000,
        min_bbox_size=0,
        score_thr=0.05,
        nms=dict(type='nms', iou_threshold=0.5),
        max_per_img=100))
dataset_type = 'VOCDataset'
data_root = 'VOC2007/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1000, 600),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=4,
    train=dict(
        type='RepeatDataset',
        times=3,
        dataset=dict(
            type='VOCDataset',
            ann_file='VOC2007/ImageSets/Main/trainval.txt',
            img_prefix='VOC2007/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', with_bbox=True),
                dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),
                dict(type='RandomFlip', flip_ratio=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size_divisor=32),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
            ])),
    val=dict(
        type='VOCDataset',
        ann_file='VOC2007/ImageSets/Main/val.txt',
        img_prefix='VOC2007/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1000, 600),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='VOCDataset',
        ann_file='VOC2007/ImageSets/Main/test.txt',
        img_prefix='VOC2007/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1000, 600),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='mAP')
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
optimizer = dict(type='SGD', lr=0.00125, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(policy='step', step=[3])
runner = dict(type='EpochBasedRunner', max_epochs=4)
work_dir = './work_dirs/advanced'
auto_resume = False
gpu_ids = [0]

2023-02-10 01:09:57,214 - mmdet - INFO - Set random seed to 1577603529, deterministic: False
2023-02-10 01:09:57,510 - mmdet - INFO - initialize ResNet with init_cfg {'type': 'Pretrained', 'checkpoint': 'torchvision://resnet50'}
2023-02-10 01:09:57,991 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2023-02-10 01:09:58,028 - mmdet - INFO - initialize RetinaHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01, 'override': {'type': 'Normal', 'name': 'retina_cls', 'std': 0.01, 'bias_prob': 0.01}}
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn1.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn2.bias - torch.Size([64]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn1.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn2.bias - torch.Size([128]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn1.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn2.bias - torch.Size([256]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn1.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn2.bias - torch.Size([512]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
PretrainedInit: load from torchvision://resnet50 

neck.lateral_convs.0.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.1.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.lateral_convs.2.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.3.conv.weight - torch.Size([256, 2048, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

neck.fpn_convs.4.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.4.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.cls_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.cls_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.reg_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.reg_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of RetinaNet  

bbox_head.retina_cls.weight - torch.Size([180, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_cls.bias - torch.Size([180]): 
NormalInit: mean=0, std=0.01, bias=-4.59511985013459 

bbox_head.retina_reg.weight - torch.Size([36, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

bbox_head.retina_reg.bias - torch.Size([36]): 
NormalInit: mean=0, std=0.01, bias=0 
2023-02-10 01:10:23,673 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2023-02-10 01:10:24,781 - mmdet - INFO - Start running, host: scz5459@g0009, work_dir: /data/run01/scz5459/mmdetection/work_dirs/advanced
2023-02-10 01:10:24,782 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-10 01:10:24,782 - mmdet - INFO - workflow: [('train', 1)], max: 4 epochs
2023-02-10 01:10:24,782 - mmdet - INFO - Checkpoints will be saved to /data/run01/scz5459/mmdetection/work_dirs/advanced by HardDiskBackend.
2023-02-10 01:11:00,599 - mmdet - INFO - Epoch [1][50/940]	lr: 1.250e-03, eta: 0:44:08, time: 0.714, data_time: 0.070, memory: 12221, loss_cls: 1.1499, loss_bbox: 0.6609, loss: 1.8108
2023-02-10 01:11:32,253 - mmdet - INFO - Epoch [1][100/940]	lr: 1.250e-03, eta: 0:41:03, time: 0.632, data_time: 0.018, memory: 12221, loss_cls: 1.1487, loss_bbox: 0.6501, loss: 1.7988
2023-02-10 01:12:04,177 - mmdet - INFO - Epoch [1][150/940]	lr: 1.250e-03, eta: 0:39:49, time: 0.639, data_time: 0.019, memory: 12221, loss_cls: 1.1485, loss_bbox: 0.6460, loss: 1.7944
2023-02-10 01:12:35,557 - mmdet - INFO - Epoch [1][200/940]	lr: 1.250e-03, eta: 0:38:45, time: 0.628, data_time: 0.018, memory: 12221, loss_cls: 1.1418, loss_bbox: 0.6355, loss: 1.7772
2023-02-10 01:13:07,588 - mmdet - INFO - Epoch [1][250/940]	lr: 1.250e-03, eta: 0:38:03, time: 0.641, data_time: 0.018, memory: 12221, loss_cls: 1.1240, loss_bbox: 0.6357, loss: 1.7597
2023-02-10 01:13:39,617 - mmdet - INFO - Epoch [1][300/940]	lr: 1.250e-03, eta: 0:37:25, time: 0.641, data_time: 0.018, memory: 12221, loss_cls: 0.9399, loss_bbox: 0.6223, loss: 1.5621
2023-02-10 01:14:10,862 - mmdet - INFO - Epoch [1][350/940]	lr: 1.250e-03, eta: 0:36:41, time: 0.625, data_time: 0.018, memory: 12221, loss_cls: 0.7624, loss_bbox: 0.5936, loss: 1.3560
2023-02-10 01:14:42,663 - mmdet - INFO - Epoch [1][400/940]	lr: 1.250e-03, eta: 0:36:05, time: 0.636, data_time: 0.018, memory: 12221, loss_cls: 0.7245, loss_bbox: 0.5700, loss: 1.2944
2023-02-10 01:15:14,959 - mmdet - INFO - Epoch [1][450/940]	lr: 1.250e-03, eta: 0:35:33, time: 0.645, data_time: 0.020, memory: 12221, loss_cls: 0.6756, loss_bbox: 0.5442, loss: 1.2198
2023-02-10 01:15:46,548 - mmdet - INFO - Epoch [1][500/940]	lr: 1.250e-03, eta: 0:34:56, time: 0.632, data_time: 0.019, memory: 12221, loss_cls: 0.6512, loss_bbox: 0.5183, loss: 1.1696
2023-02-10 01:16:18,470 - mmdet - INFO - Epoch [1][550/940]	lr: 1.250e-03, eta: 0:34:23, time: 0.639, data_time: 0.019, memory: 12221, loss_cls: 0.6492, loss_bbox: 0.5043, loss: 1.1535
2023-02-10 01:16:49,881 - mmdet - INFO - Epoch [1][600/940]	lr: 1.250e-03, eta: 0:33:47, time: 0.627, data_time: 0.018, memory: 12221, loss_cls: 0.6366, loss_bbox: 0.4905, loss: 1.1271
2023-02-10 01:17:21,418 - mmdet - INFO - Epoch [1][650/940]	lr: 1.250e-03, eta: 0:33:12, time: 0.631, data_time: 0.019, memory: 12221, loss_cls: 0.5997, loss_bbox: 0.4718, loss: 1.0715
2023-02-10 01:17:52,945 - mmdet - INFO - Epoch [1][700/940]	lr: 1.250e-03, eta: 0:32:38, time: 0.630, data_time: 0.018, memory: 12221, loss_cls: 0.6016, loss_bbox: 0.4701, loss: 1.0717
2023-02-10 01:18:25,073 - mmdet - INFO - Epoch [1][750/940]	lr: 1.250e-03, eta: 0:32:07, time: 0.643, data_time: 0.019, memory: 12221, loss_cls: 0.5761, loss_bbox: 0.4599, loss: 1.0360
2023-02-10 01:18:56,692 - mmdet - INFO - Epoch [1][800/940]	lr: 1.250e-03, eta: 0:31:33, time: 0.632, data_time: 0.018, memory: 12221, loss_cls: 0.5660, loss_bbox: 0.4480, loss: 1.0140
2023-02-10 01:19:29,008 - mmdet - INFO - Epoch [1][850/940]	lr: 1.250e-03, eta: 0:31:02, time: 0.647, data_time: 0.019, memory: 12221, loss_cls: 0.5334, loss_bbox: 0.4383, loss: 0.9717
2023-02-10 01:20:00,517 - mmdet - INFO - Epoch [1][900/940]	lr: 1.250e-03, eta: 0:30:29, time: 0.630, data_time: 0.018, memory: 12221, loss_cls: 0.5411, loss_bbox: 0.4401, loss: 0.9812
2023-02-10 01:20:25,974 - mmdet - INFO - Saving checkpoint at 1 epochs
2023-02-10 01:21:33,685 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 155  | 11784 | 0.865  | 0.041 |
| bicycle     | 177  | 6538  | 0.701  | 0.170 |
| bird        | 243  | 11052 | 0.724  | 0.050 |
| boat        | 150  | 7422  | 0.527  | 0.006 |
| bottle      | 252  | 4612  | 0.302  | 0.055 |
| bus         | 114  | 8570  | 0.763  | 0.044 |
| car         | 625  | 16867 | 0.830  | 0.437 |
| cat         | 190  | 6873  | 0.942  | 0.233 |
| chair       | 398  | 16423 | 0.774  | 0.280 |
| cow         | 123  | 6010  | 0.699  | 0.030 |
| diningtable | 112  | 3104  | 0.304  | 0.061 |
| dog         | 257  | 14507 | 0.938  | 0.105 |
| horse       | 180  | 6755  | 0.894  | 0.176 |
| motorbike   | 172  | 9365  | 0.785  | 0.067 |
| person      | 2332 | 41409 | 0.922  | 0.469 |
| pottedplant | 266  | 21624 | 0.481  | 0.030 |
| sheep       | 127  | 8896  | 0.654  | 0.040 |
| sofa        | 124  | 7011  | 0.806  | 0.031 |
| train       | 152  | 10971 | 0.895  | 0.139 |
| tvmonitor   | 158  | 11266 | 0.747  | 0.209 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.134 |
+-------------+------+-------+--------+-------+
2023-02-10 01:21:33,729 - mmdet - INFO - Exp name: advanced.py
2023-02-10 01:21:33,730 - mmdet - INFO - Epoch(val) [1][2510]	mAP: 0.1337, AP50: 0.1340
2023-02-10 01:22:08,091 - mmdet - INFO - Epoch [2][50/940]	lr: 1.250e-03, eta: 0:28:26, time: 0.684, data_time: 0.070, memory: 12221, loss_cls: 0.5426, loss_bbox: 0.4307, loss: 0.9734
2023-02-10 01:22:39,518 - mmdet - INFO - Epoch [2][100/940]	lr: 1.250e-03, eta: 0:27:57, time: 0.628, data_time: 0.018, memory: 12221, loss_cls: 0.4962, loss_bbox: 0.4233, loss: 0.9194
2023-02-10 01:23:11,435 - mmdet - INFO - Epoch [2][150/940]	lr: 1.250e-03, eta: 0:27:28, time: 0.638, data_time: 0.019, memory: 12221, loss_cls: 0.4784, loss_bbox: 0.4096, loss: 0.8881
2023-02-10 01:23:43,396 - mmdet - INFO - Epoch [2][200/940]	lr: 1.250e-03, eta: 0:27:00, time: 0.640, data_time: 0.019, memory: 12221, loss_cls: 0.5005, loss_bbox: 0.4087, loss: 0.9092
2023-02-10 01:24:14,971 - mmdet - INFO - Epoch [2][250/940]	lr: 1.250e-03, eta: 0:26:31, time: 0.631, data_time: 0.018, memory: 12221, loss_cls: 0.4744, loss_bbox: 0.4123, loss: 0.8866
2023-02-10 01:24:46,636 - mmdet - INFO - Epoch [2][300/940]	lr: 1.250e-03, eta: 0:26:01, time: 0.633, data_time: 0.018, memory: 12221, loss_cls: 0.4664, loss_bbox: 0.4067, loss: 0.8731
2023-02-10 01:25:18,209 - mmdet - INFO - Epoch [2][350/940]	lr: 1.250e-03, eta: 0:25:31, time: 0.632, data_time: 0.019, memory: 12221, loss_cls: 0.4476, loss_bbox: 0.3985, loss: 0.8462
2023-02-10 01:25:50,293 - mmdet - INFO - Epoch [2][400/940]	lr: 1.250e-03, eta: 0:25:02, time: 0.642, data_time: 0.018, memory: 12221, loss_cls: 0.4416, loss_bbox: 0.4033, loss: 0.8448
2023-02-10 01:26:21,988 - mmdet - INFO - Epoch [2][450/940]	lr: 1.250e-03, eta: 0:24:32, time: 0.633, data_time: 0.018, memory: 12221, loss_cls: 0.4283, loss_bbox: 0.3933, loss: 0.8217
2023-02-10 01:26:53,778 - mmdet - INFO - Epoch [2][500/940]	lr: 1.250e-03, eta: 0:24:02, time: 0.636, data_time: 0.019, memory: 12221, loss_cls: 0.4257, loss_bbox: 0.3995, loss: 0.8251
2023-02-10 01:27:25,705 - mmdet - INFO - Epoch [2][550/940]	lr: 1.250e-03, eta: 0:23:32, time: 0.639, data_time: 0.018, memory: 12221, loss_cls: 0.4180, loss_bbox: 0.3920, loss: 0.8100
2023-02-10 01:27:57,195 - mmdet - INFO - Epoch [2][600/940]	lr: 1.250e-03, eta: 0:23:02, time: 0.629, data_time: 0.018, memory: 12221, loss_cls: 0.4009, loss_bbox: 0.3883, loss: 0.7892
2023-02-10 01:28:28,453 - mmdet - INFO - Epoch [2][650/940]	lr: 1.250e-03, eta: 0:22:31, time: 0.625, data_time: 0.019, memory: 12221, loss_cls: 0.3748, loss_bbox: 0.3849, loss: 0.7597
2023-02-10 01:29:00,098 - mmdet - INFO - Epoch [2][700/940]	lr: 1.250e-03, eta: 0:22:00, time: 0.633, data_time: 0.019, memory: 12221, loss_cls: 0.3972, loss_bbox: 0.3891, loss: 0.7863
2023-02-10 01:29:31,769 - mmdet - INFO - Epoch [2][750/940]	lr: 1.250e-03, eta: 0:21:30, time: 0.634, data_time: 0.019, memory: 12221, loss_cls: 0.3699, loss_bbox: 0.3748, loss: 0.7447
2023-02-10 01:30:03,099 - mmdet - INFO - Epoch [2][800/940]	lr: 1.250e-03, eta: 0:20:59, time: 0.627, data_time: 0.018, memory: 12221, loss_cls: 0.3733, loss_bbox: 0.3840, loss: 0.7573
2023-02-10 01:30:34,781 - mmdet - INFO - Epoch [2][850/940]	lr: 1.250e-03, eta: 0:20:28, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.3603, loss_bbox: 0.3757, loss: 0.7359
2023-02-10 01:31:06,462 - mmdet - INFO - Epoch [2][900/940]	lr: 1.250e-03, eta: 0:19:58, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.3513, loss_bbox: 0.3788, loss: 0.7301
2023-02-10 01:31:31,649 - mmdet - INFO - Saving checkpoint at 2 epochs
2023-02-10 01:32:38,824 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 155  | 12644 | 0.935  | 0.487 |
| bicycle     | 177  | 8347  | 0.921  | 0.457 |
| bird        | 243  | 11654 | 0.918  | 0.627 |
| boat        | 150  | 6626  | 0.767  | 0.191 |
| bottle      | 252  | 5046  | 0.774  | 0.387 |
| bus         | 114  | 9131  | 0.904  | 0.227 |
| car         | 625  | 15680 | 0.941  | 0.682 |
| cat         | 190  | 8401  | 0.995  | 0.610 |
| chair       | 398  | 24335 | 0.932  | 0.469 |
| cow         | 123  | 6265  | 0.984  | 0.200 |
| diningtable | 112  | 9851  | 0.893  | 0.263 |
| dog         | 257  | 8749  | 0.988  | 0.441 |
| horse       | 180  | 8876  | 0.967  | 0.643 |
| motorbike   | 172  | 7432  | 0.942  | 0.603 |
| person      | 2332 | 44145 | 0.959  | 0.702 |
| pottedplant | 266  | 8774  | 0.726  | 0.308 |
| sheep       | 127  | 5818  | 0.858  | 0.289 |
| sofa        | 124  | 10393 | 0.976  | 0.525 |
| train       | 152  | 6008  | 0.954  | 0.481 |
| tvmonitor   | 158  | 4659  | 0.873  | 0.663 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.463 |
+-------------+------+-------+--------+-------+
2023-02-10 01:32:38,869 - mmdet - INFO - Exp name: advanced.py
2023-02-10 01:32:38,870 - mmdet - INFO - Epoch(val) [2][2510]	mAP: 0.4627, AP50: 0.4630
2023-02-10 01:33:13,590 - mmdet - INFO - Epoch [3][50/940]	lr: 1.250e-03, eta: 0:18:41, time: 0.692, data_time: 0.070, memory: 12221, loss_cls: 0.3248, loss_bbox: 0.3631, loss: 0.6879
2023-02-10 01:33:45,280 - mmdet - INFO - Epoch [3][100/940]	lr: 1.250e-03, eta: 0:18:11, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.3323, loss_bbox: 0.3658, loss: 0.6981
2023-02-10 01:34:16,795 - mmdet - INFO - Epoch [3][150/940]	lr: 1.250e-03, eta: 0:17:41, time: 0.630, data_time: 0.018, memory: 12221, loss_cls: 0.3471, loss_bbox: 0.3637, loss: 0.7108
2023-02-10 01:34:48,198 - mmdet - INFO - Epoch [3][200/940]	lr: 1.250e-03, eta: 0:17:11, time: 0.627, data_time: 0.018, memory: 12221, loss_cls: 0.3261, loss_bbox: 0.3554, loss: 0.6815
2023-02-10 01:35:19,926 - mmdet - INFO - Epoch [3][250/940]	lr: 1.250e-03, eta: 0:16:41, time: 0.635, data_time: 0.019, memory: 12221, loss_cls: 0.3164, loss_bbox: 0.3540, loss: 0.6704
2023-02-10 01:35:51,886 - mmdet - INFO - Epoch [3][300/940]	lr: 1.250e-03, eta: 0:16:11, time: 0.639, data_time: 0.018, memory: 12221, loss_cls: 0.3342, loss_bbox: 0.3549, loss: 0.6891
2023-02-10 01:36:23,980 - mmdet - INFO - Epoch [3][350/940]	lr: 1.250e-03, eta: 0:15:42, time: 0.642, data_time: 0.019, memory: 12221, loss_cls: 0.3065, loss_bbox: 0.3576, loss: 0.6641
2023-02-10 01:36:55,270 - mmdet - INFO - Epoch [3][400/940]	lr: 1.250e-03, eta: 0:15:11, time: 0.626, data_time: 0.018, memory: 12221, loss_cls: 0.3082, loss_bbox: 0.3523, loss: 0.6604
2023-02-10 01:37:27,128 - mmdet - INFO - Epoch [3][450/940]	lr: 1.250e-03, eta: 0:14:41, time: 0.637, data_time: 0.018, memory: 12221, loss_cls: 0.3066, loss_bbox: 0.3549, loss: 0.6615
2023-02-10 01:37:58,452 - mmdet - INFO - Epoch [3][500/940]	lr: 1.250e-03, eta: 0:14:10, time: 0.626, data_time: 0.018, memory: 12221, loss_cls: 0.3004, loss_bbox: 0.3499, loss: 0.6503
2023-02-10 01:38:29,775 - mmdet - INFO - Epoch [3][550/940]	lr: 1.250e-03, eta: 0:13:40, time: 0.626, data_time: 0.018, memory: 12221, loss_cls: 0.2881, loss_bbox: 0.3429, loss: 0.6310
2023-02-10 01:39:01,560 - mmdet - INFO - Epoch [3][600/940]	lr: 1.250e-03, eta: 0:13:10, time: 0.636, data_time: 0.018, memory: 12221, loss_cls: 0.3000, loss_bbox: 0.3500, loss: 0.6500
2023-02-10 01:39:32,989 - mmdet - INFO - Epoch [3][650/940]	lr: 1.250e-03, eta: 0:12:39, time: 0.629, data_time: 0.018, memory: 12221, loss_cls: 0.2942, loss_bbox: 0.3388, loss: 0.6330
2023-02-10 01:40:04,616 - mmdet - INFO - Epoch [3][700/940]	lr: 1.250e-03, eta: 0:12:08, time: 0.632, data_time: 0.018, memory: 12221, loss_cls: 0.2956, loss_bbox: 0.3408, loss: 0.6364
2023-02-10 01:40:36,293 - mmdet - INFO - Epoch [3][750/940]	lr: 1.250e-03, eta: 0:11:38, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.2886, loss_bbox: 0.3366, loss: 0.6252
2023-02-10 01:41:08,043 - mmdet - INFO - Epoch [3][800/940]	lr: 1.250e-03, eta: 0:11:07, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.2841, loss_bbox: 0.3411, loss: 0.6252
2023-02-10 01:41:39,866 - mmdet - INFO - Epoch [3][850/940]	lr: 1.250e-03, eta: 0:10:37, time: 0.637, data_time: 0.019, memory: 12221, loss_cls: 0.2757, loss_bbox: 0.3355, loss: 0.6112
2023-02-10 01:42:11,506 - mmdet - INFO - Epoch [3][900/940]	lr: 1.250e-03, eta: 0:10:06, time: 0.632, data_time: 0.018, memory: 12221, loss_cls: 0.2709, loss_bbox: 0.3297, loss: 0.6006
2023-02-10 01:42:37,031 - mmdet - INFO - Saving checkpoint at 3 epochs
2023-02-10 01:43:44,279 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 155  | 8693  | 0.968  | 0.704 |
| bicycle     | 177  | 4008  | 0.955  | 0.762 |
| bird        | 243  | 10118 | 0.951  | 0.759 |
| boat        | 150  | 9902  | 0.920  | 0.511 |
| bottle      | 252  | 8929  | 0.909  | 0.480 |
| bus         | 114  | 7062  | 0.930  | 0.560 |
| car         | 625  | 20880 | 0.981  | 0.797 |
| cat         | 190  | 5223  | 0.989  | 0.840 |
| chair       | 398  | 9835  | 0.922  | 0.576 |
| cow         | 123  | 6035  | 0.992  | 0.563 |
| diningtable | 112  | 5333  | 0.893  | 0.473 |
| dog         | 257  | 7141  | 0.992  | 0.742 |
| horse       | 180  | 5737  | 0.994  | 0.723 |
| motorbike   | 172  | 5752  | 0.977  | 0.760 |
| person      | 2332 | 37705 | 0.973  | 0.790 |
| pottedplant | 266  | 16712 | 0.914  | 0.547 |
| sheep       | 127  | 4962  | 0.913  | 0.588 |
| sofa        | 124  | 5895  | 0.976  | 0.609 |
| train       | 152  | 5670  | 0.974  | 0.718 |
| tvmonitor   | 158  | 5070  | 0.930  | 0.739 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.662 |
+-------------+------+-------+--------+-------+
2023-02-10 01:43:44,323 - mmdet - INFO - Exp name: advanced.py
2023-02-10 01:43:44,323 - mmdet - INFO - Epoch(val) [3][2510]	mAP: 0.6621, AP50: 0.6620
2023-02-10 01:44:19,000 - mmdet - INFO - Epoch [4][50/940]	lr: 1.250e-04, eta: 0:09:04, time: 0.691, data_time: 0.072, memory: 12221, loss_cls: 0.2537, loss_bbox: 0.3155, loss: 0.5692
2023-02-10 01:44:51,052 - mmdet - INFO - Epoch [4][100/940]	lr: 1.250e-04, eta: 0:08:34, time: 0.640, data_time: 0.018, memory: 12221, loss_cls: 0.2394, loss_bbox: 0.3071, loss: 0.5465
2023-02-10 01:45:22,641 - mmdet - INFO - Epoch [4][150/940]	lr: 1.250e-04, eta: 0:08:03, time: 0.632, data_time: 0.019, memory: 12221, loss_cls: 0.2346, loss_bbox: 0.3040, loss: 0.5386
2023-02-10 01:45:54,171 - mmdet - INFO - Epoch [4][200/940]	lr: 1.250e-04, eta: 0:07:33, time: 0.631, data_time: 0.018, memory: 12221, loss_cls: 0.2367, loss_bbox: 0.3023, loss: 0.5391
2023-02-10 01:46:26,155 - mmdet - INFO - Epoch [4][250/940]	lr: 1.250e-04, eta: 0:07:03, time: 0.640, data_time: 0.018, memory: 12221, loss_cls: 0.2384, loss_bbox: 0.3056, loss: 0.5440
2023-02-10 01:46:57,504 - mmdet - INFO - Epoch [4][300/940]	lr: 1.250e-04, eta: 0:06:32, time: 0.627, data_time: 0.018, memory: 12221, loss_cls: 0.2289, loss_bbox: 0.3029, loss: 0.5318
2023-02-10 01:47:29,102 - mmdet - INFO - Epoch [4][350/940]	lr: 1.250e-04, eta: 0:06:02, time: 0.632, data_time: 0.018, memory: 12221, loss_cls: 0.2269, loss_bbox: 0.3027, loss: 0.5296
2023-02-10 01:48:00,804 - mmdet - INFO - Epoch [4][400/940]	lr: 1.250e-04, eta: 0:05:31, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.2286, loss_bbox: 0.3046, loss: 0.5331
2023-02-10 01:48:31,833 - mmdet - INFO - Epoch [4][450/940]	lr: 1.250e-04, eta: 0:05:00, time: 0.621, data_time: 0.018, memory: 12221, loss_cls: 0.2399, loss_bbox: 0.3088, loss: 0.5488
2023-02-10 01:49:03,391 - mmdet - INFO - Epoch [4][500/940]	lr: 1.250e-04, eta: 0:04:30, time: 0.631, data_time: 0.018, memory: 12221, loss_cls: 0.2327, loss_bbox: 0.3077, loss: 0.5404
2023-02-10 01:49:34,766 - mmdet - INFO - Epoch [4][550/940]	lr: 1.250e-04, eta: 0:03:59, time: 0.627, data_time: 0.018, memory: 12221, loss_cls: 0.2323, loss_bbox: 0.3076, loss: 0.5399
2023-02-10 01:50:06,938 - mmdet - INFO - Epoch [4][600/940]	lr: 1.250e-04, eta: 0:03:29, time: 0.643, data_time: 0.018, memory: 12221, loss_cls: 0.2316, loss_bbox: 0.3074, loss: 0.5390
2023-02-10 01:50:39,225 - mmdet - INFO - Epoch [4][650/940]	lr: 1.250e-04, eta: 0:02:58, time: 0.646, data_time: 0.019, memory: 12221, loss_cls: 0.2362, loss_bbox: 0.3086, loss: 0.5448
2023-02-10 01:51:10,335 - mmdet - INFO - Epoch [4][700/940]	lr: 1.250e-04, eta: 0:02:27, time: 0.623, data_time: 0.018, memory: 12221, loss_cls: 0.2344, loss_bbox: 0.3058, loss: 0.5402
2023-02-10 01:51:42,119 - mmdet - INFO - Epoch [4][750/940]	lr: 1.250e-04, eta: 0:01:56, time: 0.636, data_time: 0.018, memory: 12221, loss_cls: 0.2276, loss_bbox: 0.3026, loss: 0.5303
2023-02-10 01:52:13,838 - mmdet - INFO - Epoch [4][800/940]	lr: 1.250e-04, eta: 0:01:26, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.2306, loss_bbox: 0.3003, loss: 0.5309
2023-02-10 01:52:45,617 - mmdet - INFO - Epoch [4][850/940]	lr: 1.250e-04, eta: 0:00:55, time: 0.636, data_time: 0.018, memory: 12221, loss_cls: 0.2344, loss_bbox: 0.3035, loss: 0.5379
2023-02-10 01:53:17,309 - mmdet - INFO - Epoch [4][900/940]	lr: 1.250e-04, eta: 0:00:24, time: 0.634, data_time: 0.018, memory: 12221, loss_cls: 0.2331, loss_bbox: 0.3076, loss: 0.5408
2023-02-10 01:53:42,685 - mmdet - INFO - Saving checkpoint at 4 epochs
2023-02-10 01:54:54,280 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 155  | 6522  | 0.968  | 0.754 |
| bicycle     | 177  | 5293  | 0.960  | 0.799 |
| bird        | 243  | 5940  | 0.959  | 0.829 |
| boat        | 150  | 9180  | 0.907  | 0.593 |
| bottle      | 252  | 9163  | 0.929  | 0.569 |
| bus         | 114  | 7399  | 0.965  | 0.665 |
| car         | 625  | 12925 | 0.981  | 0.831 |
| cat         | 190  | 5453  | 0.995  | 0.852 |
| chair       | 398  | 16330 | 0.967  | 0.637 |
| cow         | 123  | 5330  | 1.000  | 0.625 |
| diningtable | 112  | 7187  | 0.929  | 0.507 |
| dog         | 257  | 7153  | 0.992  | 0.808 |
| horse       | 180  | 5398  | 0.989  | 0.798 |
| motorbike   | 172  | 5851  | 0.959  | 0.788 |
| person      | 2332 | 33995 | 0.975  | 0.806 |
| pottedplant | 266  | 11653 | 0.921  | 0.597 |
| sheep       | 127  | 5191  | 0.953  | 0.649 |
| sofa        | 124  | 7014  | 0.976  | 0.638 |
| train       | 152  | 6049  | 0.980  | 0.761 |
| tvmonitor   | 158  | 6467  | 0.968  | 0.801 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.715 |
+-------------+------+-------+--------+-------+
2023-02-10 01:54:54,322 - mmdet - INFO - Exp name: advanced.py
2023-02-10 01:54:54,322 - mmdet - INFO - Epoch(val) [4][2510]	mAP: 0.7154, AP50: 0.7150
